{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aj.NesT Introduction to Data Wrangling",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SvwsksbZ4Tx"
      },
      "source": [
        "#Python Data Wrangling with Pandas by Aj.NesT the Series\n",
        "\n",
        "[Aj. NesT the Series](http://bit.ly/ajnesttheseriesSubscribe)\n",
        "\n",
        "Reference: Hands-On Data Analysis with Pandas\n",
        "\n",
        "Efficiently perform Data Collection, Wrangling, Analysis,\n",
        "and Visualization using Python\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sc2S66c-Is0"
      },
      "source": [
        "#Data Analysis Processes for Data Science"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU0JLYjQas1n"
      },
      "source": [
        "##Fundamentals of Data Analysis\n",
        "\n",
        "###Input => Data (Files -> .csv, .txt, .xlsx, SQL, JSON, API, etc.)\n",
        "###1. Data Collection\n",
        "###2. Data Wrangling (Data Cleaning --> Data Transformation --> Data Enrichment: Statistics)\n",
        "###3. Exploratory Data Analysis (EDA) --> Statistics, Machine Learning, and Data Visualization\n",
        "###4. Drawing Conclusion\n",
        "###Output => Communicate Results\n",
        "\n",
        "![alt text](https://www.glurgeek.com/wp-content/uploads/2021/09/image-62.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOtviKfKjHB_"
      },
      "source": [
        "#1. Data Collection\n",
        "![alt text](https://images.ctfassets.net/3viuren4us1n/288E0SWjmRgYQScyJeXpwt/19e6700ccf4f32dd638d73adad8279cc/data-collection---resized-3.jpg)\n",
        "**Data Collection is the natural first step for any Data Analysis**\n",
        "\n",
        "เราไม่สามารถวิเคราะห์ข้อมูลที่เราไม่ได้มีได้ ในความเป็นจริง การวิเคราะห์ข้อมูลเราสามารถเริ่มต้นได้ก่อนที่จะมีข้อมูล เพราะเมื่อเราตัดสินใจแล้วว่าเราต้องการตรวจหรืออยากวิเคราะห์ข้อมูลอะไร เราก็ต้องคิดว่าข้อมูลประเภทใดที่เราต้องทำการรวบรวม ซึ่งจะเป็นประโยชน์สำหรับการวิเคราะห์ข้อมูลของเรา โดยข้อมูลจะมาในรูปแบบใดก็ได้\n",
        "\n",
        "**รูปแบบข้อมูลที่นิยมใช้ในการสร้าง Data Collection.**\n",
        "\n",
        "1.1 Web Scraping ที่ดึงข้อมูลมาจาก HTML ของ Website (Python packages -> selenium, requests, scrapy, and beautifulsoup)\n",
        "\n",
        "1.2 APIs (Application Programming Interface) ที่ให้บริการของ Web Services (requests package)\n",
        "\n",
        "1.3 Databases เช่น SQL หรือ Database-Querying Language\n",
        "\n",
        "1.4 Internet Resouces ที่เปิดให้ดาวน์โหลดจาก Website ต่าง ๆ เช่น [Open Government Data of Thailand](https://data.go.th/), [Kaggle](https://www.kaggle.com/datasets), [COVID-19 Data Hub](https://www.tableau.com/covid-19-coronavirus-data-resources), etc.\n",
        "\n",
        "1.5 Log Files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqmm44gatMA8"
      },
      "source": [
        "#2. Data Wrangling\n",
        "\n",
        "![alt text](https://brightdata.com/wp-content/uploads/2020/04/upload_blog_20200406_083638.svg)\n",
        "\n",
        "**Data Wrangling is the process of preparing the data and getting it into a format that can be used for analysis.**\n",
        "\n",
        "**Big Problem** คือ ข้อมูลบนโลกใบนี้ไม่ได้สวยหรูแบบที่คิด ต้องนำมาปรับแต่งใหม่ให้เข้าที่เข้าทางก่อนที่จะนำมาวิเคราะห์ได้\n",
        "\n",
        "**Preprocessing** ขั้นการเตรียมข้อมูลเพื่อทำความสะอาดข้อมูล (Data Cleaning) เพื่อปรับแต่งข้อมูล พร้อมทั้งแปลงข้อมูล (Data Transformation) เพื่อเพิ่มประสิทธิภาพของข้อมูล (Data Enrichment) ให้เป็นรูปร่างที่ช่วยให้ส่วนงานทางด้านวิเคราะห์ข้อมูลสามารถนำไปใช้งานได้\n",
        "\n",
        "**รูปแบบของปัญหาที่พบเจอส่วนใหญ่**\n",
        "\n",
        "**2.1 Human Errors** ข้อมูลถูกบันทึกไม่ถูกต้อง เช่น พิมพ์ผิดใส่เลข 100 แทน 1,000 หรือข้อมูลที่บันทึกความหมายเหมือนกันแต่เขียนต่างกัน เช่น New York City, NYC และ nyc เป็นต้น\n",
        "\n",
        "**2.2 Computer Errors** บางทีเครื่องไม่ได้บันทึกข้อมูล หรือเครื่องค้าง ทำให้ข้อมูลหายเกิดเป็น Missing Data\n",
        "\n",
        "**2.3 Unexpected Values** ค่าที่ไม่คาดคิด บางทีเวลาที่บันทึกข้อมูลแล้วตัดสินใจใช้เครื่องหมาย ? สำหรับค่าที่ Missing Value ในคอลัมน์ตัวเลข Numeric ทำให้รายการข้อมูลทั้งหมดในคอลัมน์จะถือว่าเป็นข้อความ Text แทนค่าตัวเลข Numneric\n",
        "\n",
        "**2.4 Incomplete Information** ข้อมูลไม่ครบถ้วน ลองนึกถึงแบบสำรวจที่มีคำถามเพิ่มเติม ไม่ใช่ทุกคนที่จะตอบ ดังนั้นเราจึงมีข้อมูลหายไป แต่ไม่ใช่เนื่องจาก Computer Error หรือ Human Error\n",
        "\n",
        "**2.5 Resolution** ความละเอียดของข้อมูล บางทีข้อมูลอาจถูกเก็บรวบรวมต่อวินาที ในขณะที่เราต้องการข้อมูลแบบรายชั่วโมงสำหรับทำการวิเคราะห์ข้อมูล\n",
        "\n",
        "**2.6 Relevance of the Fields** ความเกี่ยวข้องกันของ Fields บางครั้งข้อมูลที่ถูกรวบรวมหรือสร้างขึ้นมาแล้วได้ผลของ Fields ที่ยังไม่สอดคล้องกัน ทำให้การวิเคราะห์ยังไม่ได้ เพื่อให้มันอยู่ในสถานะใช้งานได้ เราจะต้องทำความสะอาดข้อมูล\n",
        "\n",
        "**2.7 Format of the Data** ข้อมูลอาจถูกบันทึกในรูปแบบที่ไม่เอื้อต่อการวิเคราะห์ข้อมูล เราจะต้องทำการปรับ Format ของข้อมูลใหม่ให้ตรงกับความหมายที่ต้องการจะวิเคราะห์ข้อมูล\n",
        "\n",
        "**2.8 Misconfigurations in Data-Recording Process** การกำหนดค่าผิดพลาดในกระบวนการบันทึกข้อมูล เช่น ข้อมูลที่มาจาก Sources แหล่งที่มาที่ Misconfiguration Trackers หรือ Webhook อาจจะไม่มีฟิลด์ Missing Fields หรือการส่ง Passing ในลำดับที่ไม่ถูกต้อง\n",
        "\n",
        "**Solutions:**\n",
        "\n",
        "**Data Wrangling with Pandas** --> เขียนโปรแกรม Python Programming มาใช้ในการเตรียมข้อมูล Preprocessing (Data Cleaning --> Data Transformation --> Data Enrichment)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aiPDWr7GAU0"
      },
      "source": [
        "#3. Exploratory Data Analysis\n",
        "\n",
        "![alt text](https://www.researchgate.net/publication/329930775/figure/fig3/AS:873046667710469@1585161954284/The-fundamental-steps-of-the-exploratory-data-analysis-process_W640.jpg)\n",
        "\n",
        "**During Exploratory Data Analysis (EDA), we use visualizations and summary statistics to get a better understanding of the data.**\n",
        "\n",
        "การวิเคราะห์ข้อมูลเชิงสำรวจ เราใช้การแสดงภาพข้อมูลและสถิติ มาช่วยวิเคราะห์ เพื่อสรุปให้เข้าใจข้อมูลได้ดีขึ้น เนื่องจากสมองของมนุษย์มีความชำนาญในการเลือกรูปแบบการมองเห็น การแสดงข้อมูลจึงมีความสำคัญต่อการวิเคราะห์ อันที่จริง คุณลักษณะบางอย่างของข้อมูลสามารถสังเกตได้เฉพาะในผ่านการ Plot Charts ขึ้นอยู่กับข้อมูลของเรา เราอาจ Plot Charts\n",
        "เพื่อดูว่าตัวแปรที่น่าสนใจมีวิวัฒนาการอย่างไรเมื่อเวลาผ่านไป เปรียบเทียบจำนวนการสังเกตของแต่ละหมวดหมู่ ค้นหาค่าผิดปกติ ดูการกระจายของตัวแปรต่อเนื่องและตัวแปรแบบไม่ต่อเนื่อง และอื่น ๆ อีกมากมาย ซึ่งคนที่ทำงานสายนี้ต้องมีความรู้ทางด้าน Statistics, Machine Learning และ Data Visualization ถึงจะเป็นนักวิเคราะห์ข้อมูลเชิงลึกได้อย่างมีประสิทธิภาพ\n",
        "\n",
        "**ความสัมพันธ์ของ Exploratory Data Analysis กับ Data Wrangling**\n",
        "\n",
        "**3.1 Data จำเป็นต้องเตรียมก่อนทำ Exploratory Data Analysis**\n",
        "\n",
        "**3.2 การแสดงภาพ Data Visualization ที่สร้างขึ้นระหว่างกระบวนการ EDA**  จะสามารถบอกถึงความจำเป็นในการทำความสะอาดข้อมูล Data Cleaning ได้\n",
        "\n",
        "**3.3 Data Wrangling จะใช้ Statistics เพื่อค้นหาปัญหาข้อมูลที่อาจเกิดขึ้น ในขณะที่ EDA ใช้เพื่อทำความเข้าใจข้อมูล โดยการทำความสะอาดที่ไม่เหมาะสมจะบิดเบือนสิ่งที่ค้นพบในขั้นของ EDA**\n",
        "\n",
        "**3.4 Data Wrangling Skills will be required to get summary statistics across subsets of the data.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPps-hIPMCtW"
      },
      "source": [
        "#4. Drawing Conclusions\n",
        "\n",
        "![alt text](https://s3.amazonaws.com/blog.site/images/how%20to%20write%20a%20research%20paper%20conclusion%20(1)_1554820948.jpg)\n",
        "\n",
        "**Drawing Conclusions ขั้นของการสรุปการวิเคราะห์ข้อมูล Data Analysis**\n",
        "\n",
        "หลังจากที่เราได้ทำ Data Collection รวบรวมข้อมูลสำหรับการวิเคราะห์ Data Wrangling (Data Cleaning --> Data Transformation --> Data Enrichment) และดำเนินการทำ Exploratory Data Analysis (EDA) อย่างละเอียดแล้ว ก็ถึงเวลาสรุปผล นี่คือที่ที่เราสรุปการค้นพบของเราจาก Exploratory Data Analysis (EDA) \n",
        "\n",
        "**ตัดสินใจขั้นตอนต่อไป:**\n",
        "\n",
        "**4.1 เราสังเกตเห็นรูปแบบ Patterns หรือความสัมพันธ์ Relationships เมื่อแสดงข้อมูลเป็นภาพ Data Visualization หรือไม่?**\n",
        "\n",
        "**4.2 เราสามารถคาดการณ์ Predictions จากข้อมูลของเราได้อย่างแม่นยำหรือไม่?**\n",
        "\n",
        "**4.3 เหมาะสมที่จะย้ายไปสร้างแบบจำลองข้อมูล Data Modeling หรือไม่?**\n",
        "\n",
        "**4.4 ข้อมูลมีการกระจาย Data Distribution อย่างไร?**\n",
        "\n",
        "**4.5 ข้อมูลช่วยให้เราตอบคำถามที่เรามีหรือให้ข้อมูลเชิงลึก Business Insights เกี่ยวกับปัญหาที่เรากำลังตรวจสอบหรือไม่?**\n",
        "\n",
        "**4.6 เราจำเป็นต้องรวบรวมข้อมูลใหม่ หรือ ข้อมูลเพิ่มเติมหรือไม่?** \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm18bFngSUgs"
      },
      "source": [
        "#Let's Understand All About Data Wrangling!\n",
        "\n",
        "##Data Wrangling Workshop\n",
        "\n",
        "เปิด Website http://vis.stanford.edu/wrangler/ \n",
        "\n",
        "ทดลองฝึกปฏิบัติการทำ Data Wrangling ด้วยโปรแกรม Wrangler ซึ่งเป็น Interactive Tool สำหรับทำความสะอาดข้อมูล Data Cleaning และทำการแปลงข้อมูล Data Transformation ช่วยให้ใช้เวลาในการจัดรูปแบบน้อยลง และมีเวลามากขึ้นในการวิเคราะห์ข้อมูล Output ของการทดลองนี้ \n",
        "\n",
        "สามารถนำไปใช้ส่งออกข้อมูลเพื่อใช้ใน Excel, R, Tableau, Power BI, Google Data Studio, Protovis, etc."
      ]
    }
  ]
}