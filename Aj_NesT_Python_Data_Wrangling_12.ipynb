{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aj.NesT - Python Data Wrangling #12",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtrCo05tRE73"
      },
      "source": [
        "#Data Wrangling with Pandas\n",
        "\n",
        "[Aj. NesT the Series](http://bit.ly/ajnesttheseriesSubscribe)\n",
        "\n",
        "Referenence: [Pyhton Data Cleaning Cookbook 2020](https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook)\n",
        "\n",
        "##Practice 3: สร้างฟังก์ชันและคลาสที่กำหนดโดยผู้ใช้เพื่อทำความสะอาดข้อมูลแบบอัตโนมัติ\n",
        "\n",
        "--> User-Defined Functions and Classes to Automate Data Cleaning\n",
        "\n",
        "[Python Pandas Cheat Sheets](https://www.enthought.com/wp-content/uploads/Enthought-Python-Pandas-Cheat-Sheets-1-8-v1.0.2.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYvmolVuVVMN"
      },
      "source": [
        "##Workshop 12: สร้างฟังก์ชันแสดง Summary Statistics และ Frequencies\n",
        "--> Functions for displaying summary statistics and frequencies\n",
        "\n",
        "###Input Datasets\n",
        "\n",
        "* **[nls97f.csv](https://drive.google.com/file/d/1t9YHxkeCr4CUQqy8XDDu_RKM9uMKr0BP/view?usp=sharing)** - The survey started with a cohort\n",
        "of individuals in 1997 who were born between 1980 and 1985, with annual\n",
        "follow-ups each year through 2017. the National Longitudinal Survey (NLS) 1997-2017. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mySii_FKZZz-"
      },
      "source": [
        "####Question 12: สร้างฟังก์ชัน getmissings, gettots, makefreqs และ getcnts เพิ่มเติมต้องเขียนอย่างไรบ้าง?\n",
        "\n",
        "**STEP 1:** นำเข้า Datasets โดยทำการ Upload ไฟล์ nls97f.csv ขึ้น Google Colab (ไฟล์นี้จะถูกลบเมื่อเราหลุดจาก Session หรือปิด Browser) หรือ Python IDE เช่น PyCharm, VSCode, Juputer Notebook, etc.\n",
        "\n",
        "**STEP 2:** เขียนโปรแกรมเพื่อสร้างฟังก์ชันต่าง ๆ รวม 6 functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YIssfaTQMPI"
      },
      "source": [
        "#Define Functions\n",
        "#(1) get first look\n",
        "def getfirstlook(df, nrows=5, uniqueids=None):\n",
        "  out = {}\n",
        "  out['head'] = df.head(nrows)\n",
        "  out['dtypes'] = df.dtypes\n",
        "  out['nrows'] = df.shape[0]\n",
        "  out['ncols'] = df.shape[1]\n",
        "  out['index'] = df.index\n",
        "  if (uniqueids is not None):\n",
        "    out['uniqueids'] = df[uniqueids].nunique()\n",
        "  return out\n",
        "\n",
        "#(2) displaydict\n",
        "def displaydict(dicttodisplay):\n",
        "  print(*(': '.join(map(str, x)) \\\n",
        "    for x in dicttodisplay.items()), sep='\\n\\n')\n",
        "\n",
        "#(3) get summary statistics\n",
        "def gettots(df):\n",
        "  out = {}\n",
        "  out['min'] = df.min()\n",
        "  out['per15'] = df.quantile(0.15)\n",
        "  out['qr1'] = df.quantile(0.25)\n",
        "  out['med'] = df.median()\n",
        "  out['qr3'] = df.quantile(0.75)\n",
        "  out['per85'] = df.quantile(0.85)\n",
        "  out['max'] = df.max()\n",
        "  out['count'] = df.count()\n",
        "  out['mean'] = df.mean()\n",
        "  out['iqr'] = out['qr3']-out['qr1']\n",
        "  return pd.DataFrame(out)\n",
        "\n",
        "#(4) count missings by columns and rows\n",
        "def getmissings(df, byrowperc=False):\n",
        "  return df.isnull().sum(),\\\n",
        "    df.isnull().sum(axis=1).value_counts(normalize=byrowperc).sort_index()\n",
        "\n",
        "#(5) do frequencies and percentages for all category variables in data frame\n",
        "def makefreqs(df, outfile):\n",
        "  freqout = open(outfile, 'w') \n",
        "  for col in df.select_dtypes(include=[\"category\"]):\n",
        "    print(col, \"----------------------\", \"frequencies\",\n",
        "    df[col].value_counts().sort_index(),\"percentages\",\n",
        "    df[col].value_counts(normalize=True).sort_index(),\n",
        "    sep=\"\\n\\n\", end=\"\\n\\n\\n\", file=freqout)\n",
        "\n",
        "  freqout.close()\n",
        "\n",
        "#(6) get counts by groupings\n",
        "def getcnts(df, cats, rowsel=None):\n",
        "  tots = cats[:-1]\n",
        "  catcnt = df.groupby(cats).size().reset_index(name='catcnt')\n",
        "  totcnt = df.groupby(tots).size().reset_index(name='totcnt')\n",
        "  percs = pd.merge(catcnt, totcnt, left_on=tots, \n",
        "    right_on=tots, how=\"left\")\n",
        "  percs['percent'] = percs.catcnt / percs.totcnt\n",
        "  if (rowsel is not None):\n",
        "    percs = percs.loc[eval(\"percs.\" + rowsel)]\n",
        "  return percs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k8IB6y2D9fM"
      },
      "source": [
        "**STEP 3:** นำเข้า pandas librariey มาใช้งาน\n",
        "\n",
        "**STEP 4:** ทำการอ่านไฟล์ .csv ด้วย pandas เก็บเป็น Dataframe\n",
        "\n",
        "ใช้คำสั่ง .read_csv()\n",
        "\n",
        "**STEP 5:** ตั้งค่าและแสดง index และ size ของ nls97f data\n",
        "\n",
        "ใช้คำสั่ง set_index()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMKrkyG08GE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab2978bf-bab9-45b0-8a70-45e7ba37d2cc"
      },
      "source": [
        "#import pandas library\n",
        "import pandas as pd\n",
        "nls97 = pd.read_csv(\"/content/nls97f.csv\")\n",
        "print(nls97)\n",
        "nls97.set_index('personid', inplace=True)\n",
        "print(nls97)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      personid  gender  birthmonth  ...      colenrfeb17      colenroct17 originalid\n",
            "0       100061  Female           5  ...  1. Not enrolled  1. Not enrolled       8245\n",
            "1       100139    Male           9  ...  1. Not enrolled  1. Not enrolled       3962\n",
            "2       100284    Male          11  ...  1. Not enrolled  1. Not enrolled       3571\n",
            "3       100292    Male           4  ...              NaN              NaN       2979\n",
            "4       100583    Male           1  ...  1. Not enrolled  1. Not enrolled       8511\n",
            "...        ...     ...         ...  ...              ...              ...        ...\n",
            "8979    999291  Female           4  ...  1. Not enrolled  1. Not enrolled       7217\n",
            "8980    999406    Male           7  ...  1. Not enrolled  1. Not enrolled          2\n",
            "8981    999543  Female           8  ...  1. Not enrolled  1. Not enrolled       5113\n",
            "8982    999698  Female           5  ...  1. Not enrolled  1. Not enrolled       7815\n",
            "8983    999963  Female           9  ...  1. Not enrolled  1. Not enrolled        166\n",
            "\n",
            "[8984 rows x 90 columns]\n",
            "          gender  birthmonth  ...      colenroct17  originalid\n",
            "personid                      ...                             \n",
            "100061    Female           5  ...  1. Not enrolled        8245\n",
            "100139      Male           9  ...  1. Not enrolled        3962\n",
            "100284      Male          11  ...  1. Not enrolled        3571\n",
            "100292      Male           4  ...              NaN        2979\n",
            "100583      Male           1  ...  1. Not enrolled        8511\n",
            "...          ...         ...  ...              ...         ...\n",
            "999291    Female           4  ...  1. Not enrolled        7217\n",
            "999406      Male           7  ...  1. Not enrolled           2\n",
            "999543    Female           8  ...  1. Not enrolled        5113\n",
            "999698    Female           5  ...  1. Not enrolled        7815\n",
            "999963    Female           9  ...  1. Not enrolled         166\n",
            "\n",
            "[8984 rows x 89 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfB6BKmo01PU"
      },
      "source": [
        "**STEP 6:** เรียกใช้ฟังก์ชัน gettots() เพื่อแสดงค่า summary statistcs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3HZR78q1OXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f58ba7-5874-49eb-dd08-613fc77720fa"
      },
      "source": [
        "#show summary statistics for continuous variables\n",
        "print(gettots(nls97[['satverbal','satmath']]).T)\n",
        "print()\n",
        "print(gettots(nls97.filter(like=\"weeksworked\")))  #Filter เอาเฉพาะ columns ที่มีชื่อคำว่า weeksworked"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        satverbal      satmath\n",
            "min      14.00000     7.000000\n",
            "per15   390.00000   390.000000\n",
            "qr1     430.00000   430.000000\n",
            "med     500.00000   500.000000\n",
            "qr3     570.00000   580.000000\n",
            "per85   620.00000   621.000000\n",
            "max     800.00000   800.000000\n",
            "count  1406.00000  1407.000000\n",
            "mean    499.72404   500.590618\n",
            "iqr     140.00000   150.000000\n",
            "\n",
            "               min  per15   qr1   med  ...   max  count       mean   iqr\n",
            "weeksworked00  0.0    0.0   5.0  26.0  ...  53.0   8603  26.417761  45.0\n",
            "weeksworked01  0.0    0.0  10.0  33.0  ...  52.0   8564  29.784096  41.0\n",
            "weeksworked02  0.0    0.0  13.0  38.0  ...  52.0   8556  31.805400  39.0\n",
            "weeksworked03  0.0    0.0  14.0  43.0  ...  52.0   8490  33.469611  38.0\n",
            "weeksworked04  0.0    1.0  18.0  46.0  ...  52.0   8458  35.104635  34.0\n",
            "weeksworked05  0.0    5.0  22.0  50.0  ...  53.0   8403  37.316435  31.0\n",
            "weeksworked06  0.0    9.0  27.0  51.0  ...  52.0   8340  38.429976  25.0\n",
            "weeksworked07  0.0   10.0  30.0  52.0  ...  52.0   8272  39.241296  22.0\n",
            "weeksworked08  0.0    9.0  30.0  52.0  ...  52.0   8186  39.287564  22.0\n",
            "weeksworked09  0.0    0.0  22.0  52.0  ...  52.0   8146  37.419961  30.0\n",
            "weeksworked10  0.0    0.0  20.0  52.0  ...  52.0   8054  37.029923  32.0\n",
            "weeksworked11  0.0    0.0  22.0  53.0  ...  53.0   7968  37.911270  31.0\n",
            "weeksworked12  0.0    0.0  22.0  52.0  ...  52.0   7747  38.036918  30.0\n",
            "weeksworked13  0.0    0.0  28.0  52.0  ...  52.0   7680  38.791016  24.0\n",
            "weeksworked14  0.0    0.0  23.0  52.0  ...  52.0   7612  38.316999  29.0\n",
            "weeksworked15  0.0    0.0  33.0  52.0  ...  52.0   7389  39.605630  19.0\n",
            "weeksworked16  0.0    0.0  23.0  53.0  ...  53.0   7068  39.127476  30.0\n",
            "weeksworked17  0.0    0.0  37.0  49.0  ...  52.0   6670  39.016642  15.0\n",
            "\n",
            "[18 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q90QguZeC9LZ"
      },
      "source": [
        "**STEP 7:** เรียกใช้ฟังก์ชัน getmissings() เพื่อนับจำนวน missing data ต่อ column และต่อ row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsCB0TN_Oy_M",
        "outputId": "ff598b9a-56c1-4e19-8636-43a1ac6651c7"
      },
      "source": [
        "#count missing per column and per row\n",
        "missingsbycols, missingsbyrows = getmissings(nls97[['weeksworked16','weeksworked17']])\n",
        "print(missingsbycols)\n",
        "print()\n",
        "print(missingsbyrows)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weeksworked16    1916\n",
            "weeksworked17    2314\n",
            "dtype: int64\n",
            "\n",
            "0    6641\n",
            "1     456\n",
            "2    1887\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWEfFFw9Zl78"
      },
      "source": [
        "**STEP 8:** เรียกใช้ฟังก์ชัน makefreqs เพื่อรับความถี่ของ categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A0633L6aQBS"
      },
      "source": [
        "#do frequencies for categorical columns\n",
        "#แปลง data types จาก object ให้เป็น category\n",
        "nls97.loc[:, nls97.dtypes == 'object'] = \\\n",
        "  nls97.select_dtypes(['object']). \\\n",
        "  apply(lambda x: x.astype('category'))\n",
        "#เรียกใช้ฟังก์ชัน makefreqs เขียนไฟล์แสดงจำนวนความถี่ที่นับได้\n",
        "makefreqs(nls97, \"/content/nlsfreqs.txt\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3LDq6SDElBi"
      },
      "source": [
        "**STEP 9:** เรียกใช้ฟังก์ชัน getcnts นับจำนวนและ % ตาม groups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXXLieXgElbB",
        "outputId": "4ff9de81-3620-4ba2-8ea3-95bc88c8b38e"
      },
      "source": [
        "#do counts and percentages by groups\n",
        "print(getcnts(nls97, ['maritalstatus','gender','colenroct00']))\n",
        "print()\n",
        "print(getcnts(nls97, ['maritalstatus','gender','colenroct00'], \"colenroct00.str[0:1]=='1'\"))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    maritalstatus  gender         colenroct00  catcnt  totcnt   percent\n",
            "0        Divorced  Female     1. Not enrolled     317     393  0.806616\n",
            "1        Divorced  Female  2. 2-year college       35     393  0.089059\n",
            "2        Divorced  Female   3. 4-year college      41     393  0.104326\n",
            "3        Divorced    Male     1. Not enrolled     238     270  0.881481\n",
            "4        Divorced    Male  2. 2-year college       15     270  0.055556\n",
            "5        Divorced    Male   3. 4-year college      17     270  0.062963\n",
            "6         Married  Female     1. Not enrolled    1168    1636  0.713936\n",
            "7         Married  Female  2. 2-year college      143    1636  0.087408\n",
            "8         Married  Female   3. 4-year college     325    1636  0.198655\n",
            "9         Married    Male     1. Not enrolled    1094    1430  0.765035\n",
            "10        Married    Male  2. 2-year college       93    1430  0.065035\n",
            "11        Married    Male   3. 4-year college     243    1430  0.169930\n",
            "12  Never-married  Female     1. Not enrolled    1094    1307  0.837031\n",
            "13  Never-married  Female  2. 2-year college       65    1307  0.049732\n",
            "14  Never-married  Female   3. 4-year college     148    1307  0.113236\n",
            "15  Never-married    Male     1. Not enrolled    1268    1459  0.869088\n",
            "16  Never-married    Male  2. 2-year college       66    1459  0.045236\n",
            "17  Never-married    Male   3. 4-year college     125    1459  0.085675\n",
            "18      Separated  Female     1. Not enrolled      66      79  0.835443\n",
            "19      Separated  Female  2. 2-year college        8      79  0.101266\n",
            "20      Separated  Female   3. 4-year college       5      79  0.063291\n",
            "21      Separated    Male     1. Not enrolled      67      75  0.893333\n",
            "22      Separated    Male  2. 2-year college        5      75  0.066667\n",
            "23      Separated    Male   3. 4-year college       3      75  0.040000\n",
            "24        Widowed  Female     1. Not enrolled      16      19  0.842105\n",
            "25        Widowed  Female  2. 2-year college        1      19  0.052632\n",
            "26        Widowed  Female   3. 4-year college       2      19  0.105263\n",
            "27        Widowed    Male     1. Not enrolled       3       4  0.750000\n",
            "28        Widowed    Male  2. 2-year college        0       4  0.000000\n",
            "29        Widowed    Male   3. 4-year college       1       4  0.250000\n",
            "\n",
            "    maritalstatus  gender      colenroct00  catcnt  totcnt   percent\n",
            "0        Divorced  Female  1. Not enrolled     317     393  0.806616\n",
            "3        Divorced    Male  1. Not enrolled     238     270  0.881481\n",
            "6         Married  Female  1. Not enrolled    1168    1636  0.713936\n",
            "9         Married    Male  1. Not enrolled    1094    1430  0.765035\n",
            "12  Never-married  Female  1. Not enrolled    1094    1307  0.837031\n",
            "15  Never-married    Male  1. Not enrolled    1268    1459  0.869088\n",
            "18      Separated  Female  1. Not enrolled      66      79  0.835443\n",
            "21      Separated    Male  1. Not enrolled      67      75  0.893333\n",
            "24        Widowed  Female  1. Not enrolled      16      19  0.842105\n",
            "27        Widowed    Male  1. Not enrolled       3       4  0.750000\n"
          ]
        }
      ]
    }
  ]
}